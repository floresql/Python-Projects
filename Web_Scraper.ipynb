{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cf0170-6eb4-4355-a510-6442a2531f24",
   "metadata": {},
   "source": [
    "# Scraping URLs in Python with `urllib` and `BeautifulSoup`\n",
    "\n",
    "Python provides a built-in module, `urllib`, to work with URLs. Here's how you can use it alongside `BeautifulSoup` to scrape data from a website.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Initialize the Scraper Class**\n",
    "   - The `__init__` method initializes the Scraper class with a URL as a parameter.\n",
    "   - Example: Pass `\"https://news.google.com/\"` as the parameter during initialization.\n",
    "\n",
    "2. **Retrieve HTML**\n",
    "   - The `scrape` method uses the `urlopen()` function to send a request to the specified website.\n",
    "   - The function returns a `Response` object containing:\n",
    "     - HTML code of the website.\n",
    "     - Metadata about the response.\n",
    "   - Use the `read()` method to extract the HTML and store it in a variable like `html`.\n",
    "\n",
    "3. **Parse the HTML**\n",
    "   - Use `BeautifulSoup` to parse the HTML. This step makes the HTML easy to search and process:\n",
    "     ```python\n",
    "     from bs4 import BeautifulSoup\n",
    "     soup = BeautifulSoup(html, \"html.parser\")\n",
    "     ```\n",
    "\n",
    "4. **Extract Links**\n",
    "   - Use the `find_all` method to retrieve all `<a>` tags (hyperlinks):\n",
    "     ```python\n",
    "     links = soup.find_all(\"a\")\n",
    "     ```\n",
    "   - Iterate through the returned tags and extract the `href` attribute (the actual URL) using the `get()` method:\n",
    "     ```python\n",
    "     for link in links:\n",
    "         url = link.get(\"href\")\n",
    "         if url and \"topics\" in url:  # Filter URLs containing the string \"topics\"\n",
    "             print(url)\n",
    "     ```\n",
    "\n",
    "### Example Implementation\n",
    "Below is a complete example of how this process could be implemented:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e15b16-1fcf-469c-9563-1b354b37fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./topics/CAAqIggKIhxDQkFTRHdvSkwyMHZNRGxqTjNjd0VnSmxiaWdBUAE?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx1YlY4U0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqHAgKIhZDQklTQ2pvSWJHOWpZV3hmZGpJb0FBUAE?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNREpxYW5RU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp1ZEdvU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp0Y1RjU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqIQgKIhtDQkFTRGdvSUwyMHZNR3QwTlRFU0FtVnVLQUFQAQ?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRFZxYUdjU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen\n",
      "./topics/CAAqHAgKIhZDQklTQ2pvSWJHOWpZV3hmZGpJb0FBUAE?hl=en-US&gl=US&ceid=US%3Aen\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "    def scrape(self):\n",
    "        response = urlopen(self.url)  # Fetch the HTML from the website\n",
    "        html = response.read()  # Read the HTML content\n",
    "        soup = BeautifulSoup(html, \"html.parser\")  # Parse the HTML with BeautifulSoup\n",
    "\n",
    "        links = soup.find_all(\"a\")  # Find all anchor tags\n",
    "        for link in links:\n",
    "            url = link.get(\"href\")  # Get the href attribute\n",
    "            if url and \"topics\" in url:  # Filter links containing \"topics\"\n",
    "                print(url)\n",
    "\n",
    "# Example usage\n",
    "scraper = Scraper(\"https://news.google.com/\")\n",
    "scraper.scrape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
